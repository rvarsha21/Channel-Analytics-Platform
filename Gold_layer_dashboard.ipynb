{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "notebookId": "574zxggpuswwdqs242ys",
   "authorId": "7233590265658",
   "authorName": "KOALA",
   "authorEmail": "",
   "sessionId": "8142185b-bf3a-4b15-809e-3172faf92822",
   "lastEditTime": 1764962367049
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "language": "python",
    "name": "cell1"
   },
   "source": "import streamlit as st\nfrom snowflake.snowpark.context import get_active_session\nimport pandas as pd\n\n# ---------------------------------------------------\n# Page setup\n# ---------------------------------------------------\n# Remove this line if st.set_page_config is already called earlier in your app.\n# st.set_page_config(layout=\"wide\")\n\nst.title(\"YouTube Channels â€“ Gold Layer Dashboard\")\nst.caption(\n    \"Built on DB_TEAM_VRR.GOLD tables: \"\n    \"CHANNEL_GROWTH_METRICS, CHANNEL_EFFICIENCY_LEADERBOARD, COUNTRY_PORTFOLIO_SHARE\"\n)\n\nsession = get_active_session()\n\n# ---------------------------------------------------\n# Helper: cached loader + refresh\n# ---------------------------------------------------\ndef load_or_cache(query: str, key: str) -> pd.DataFrame:\n    if key not in st.session_state:\n        df = session.sql(query).to_pandas()\n        st.session_state[key] = df\n    return st.session_state[key]\n\n# Refresh button to clear cached dataframes\nif st.button(\"ðŸ”„ Refresh data from Snowflake\"):\n    for k in [\"growth_df\", \"eff_df\", \"port_df\"]:\n        st.session_state.pop(k, None)\n    st.success(\"Data cache cleared. Latest data will be loaded from Snowflake on this run.\")\n\n# ---------------------------------------------------\n# Load Gold data\n# ---------------------------------------------------\ngrowth_query = \"\"\"\nSELECT *\nFROM DB_TEAM_VRR.GOLD.CHANNEL_GROWTH_METRICS;\n\"\"\"\n\neff_query = \"\"\"\nSELECT *\nFROM DB_TEAM_VRR.GOLD.CHANNEL_EFFICIENCY_LEADERBOARD;\n\"\"\"\n\nportfolio_query = \"\"\"\nSELECT *\nFROM DB_TEAM_VRR.GOLD.COUNTRY_PORTFOLIO_SHARE;\n\"\"\"\n\ngrowth_df = load_or_cache(growth_query, \"growth_df\")\neff_df = load_or_cache(eff_query, \"eff_df\")\nport_df = load_or_cache(portfolio_query, \"port_df\")\n\n# Normalize LOAD_DATE as full datetime (keep time component)\nfor df in (growth_df, port_df):\n    if \"LOAD_DATE\" in df.columns:\n        df[\"LOAD_DATE\"] = pd.to_datetime(df[\"LOAD_DATE\"])\n\nst.markdown(\"---\")\n\n# ===================================================\n# 1) Top Channels by Subscribers (Bar chart)\n# ===================================================\n\nst.subheader(\"1. Top Channels by Subscribers (by Load Date / Time)\")\n\ncol1, col2, col3 = st.columns(3)\n\n# Load date/time filter\nwith col1:\n    available_loads = sorted(growth_df[\"LOAD_DATE\"].dropna().unique())\n    if len(available_loads) == 0:\n        selected_load = None\n        st.warning(\"No LOAD_DATE values found in growth data.\")\n    else:\n        selected_load = st.selectbox(\n            \"Load Date / Time\",\n            options=available_loads,\n            index=len(available_loads) - 1,\n            key=\"growth_load_datetime\",\n            format_func=lambda x: x.strftime(\"%Y-%m-%d %H:%M:%S\"),\n        )\n\n# Category filter\nwith col2:\n    categories = sorted(growth_df[\"CATEGORY_NAME\"].dropna().unique().tolist())\n    selected_category = st.selectbox(\n        \"Category (optional)\",\n        options=[\"All\"] + categories,\n        key=\"growth_category\",\n    )\n\n# Country filter\nwith col3:\n    countries = sorted(growth_df[\"COUNTRY_CODE\"].dropna().unique().tolist())\n    selected_country = st.selectbox(\n        \"Country (optional)\",\n        options=[\"All\"] + countries,\n        key=\"growth_country\",\n    )\n\nif selected_load is not None:\n    g = growth_df[growth_df[\"LOAD_DATE\"] == selected_load].copy()\n\n    if selected_category != \"All\":\n        g = g[g[\"CATEGORY_NAME\"] == selected_category]\n\n    if selected_country != \"All\":\n        g = g[g[\"COUNTRY_CODE\"] == selected_country]\n\n    # Sort by subscriber count and take top 10\n    g = g.sort_values(\"SUBSCRIBER_COUNT\", ascending=False).head(10)\n\n    if g.empty:\n        st.info(\"No channels found for the selected filters.\")\n    else:\n        chart_data = g.set_index(\"CHANNEL_NAME\")[\"SUBSCRIBER_COUNT\"]\n        st.bar_chart(chart_data)\n        st.dataframe(\n            g[\n                [\n                    \"CHANNEL_NAME\",\n                    \"CATEGORY_NAME\",\n                    \"COUNTRY_CODE\",\n                    \"SUBSCRIBER_COUNT\",\n                    \"VIEW_COUNT\",\n                    \"GROWTH_LABEL\",\n                    \"LOAD_DATE\",\n                ]\n            ],\n            use_container_width=True,\n        )\n\nst.markdown(\"---\")\n\n# ===================================================\n# 2) Efficiency Scatter â€“ Subscribers vs Views per Video\n# ===================================================\n\nst.subheader(\"2. Channel Efficiency â€“ Subscribers vs Views per Video\")\n\ncol4, col5 = st.columns(2)\n\nwith col4:\n    eff_cat = st.selectbox(\n        \"Filter by Category\",\n        options=[\"All\"] + sorted(eff_df[\"CATEGORY_NAME\"].dropna().unique().tolist()),\n        key=\"eff_category\",\n    )\n\nwith col5:\n    eff_country = st.selectbox(\n        \"Filter by Country\",\n        options=[\"All\"] + sorted(eff_df[\"COUNTRY_CODE\"].dropna().unique().tolist()),\n        key=\"eff_country\",\n    )\n\ne = eff_df.copy()\ne = e[(e[\"SUBSCRIBER_COUNT\"] > 0) & (e[\"VIEWS_PER_VIDEO\"] > 0)]\n\nif eff_cat != \"All\":\n    e = e[e[\"CATEGORY_NAME\"] == eff_cat]\n\nif eff_country != \"All\":\n    e = e[e[\"COUNTRY_CODE\"] == eff_country]\n\nif e.empty:\n    st.info(\"No channels found for efficiency plot with current filters.\")\nelse:\n    # Limit number of points for plotting sanity\n    e_sample = e.head(300).copy()\n    scatter_data = (\n        e_sample[[\"CHANNEL_NAME\", \"SUBSCRIBER_COUNT\", \"VIEWS_PER_VIDEO\"]]\n        .set_index(\"CHANNEL_NAME\")\n    )\n\n    st.scatter_chart(\n        scatter_data,\n        x=\"SUBSCRIBER_COUNT\",\n        y=\"VIEWS_PER_VIDEO\",\n    )\n\n    st.caption(\n        \"Each point is a channel. Higher VIEWS_PER_VIDEO for a given subscriber \"\n        \"count indicates more efficient content.\"\n    )\n\n    st.dataframe(\n        e.sort_values(\"VPV_EFFICIENCY_INDEX\", ascending=False).head(20)[\n            [\n                \"CHANNEL_NAME\",\n                \"CATEGORY_NAME\",\n                \"COUNTRY_CODE\",\n                \"SUBSCRIBER_COUNT\",\n                \"VIEWS_PER_VIDEO\",\n                \"VPV_EFFICIENCY_INDEX\",\n                \"VPS_EFFICIENCY_INDEX\",\n            ]\n        ],\n        use_container_width=True,\n    )\n\nst.markdown(\"---\")\n",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "8d50cbf4-0c8d-4950-86cb-114990437ac9",
   "metadata": {
    "language": "python",
    "name": "cell2",
    "codeCollapsed": false
   },
   "source": "import streamlit as st\nfrom snowflake.snowpark.context import get_active_session\nimport pandas as pd\n\nst.subheader(\"Channel Size Distribution â€“ Tiny vs Giants\")\n\nsession = get_active_session()\n\n# ---------------------------------------------\n# Refresh button & cached loader\n# ---------------------------------------------\ndef load_efficiency_df() -> pd.DataFrame:\n    if \"eff_df\" not in st.session_state:\n        df = session.sql(\"\"\"\n            SELECT LOAD_DATE,\n                   CHANNEL_NAME,\n                   SUBSCRIBER_COUNT,\n                   VIEW_COUNT\n            FROM DB_TEAM_VRR.GOLD.CHANNEL_EFFICIENCY_LEADERBOARD\n        \"\"\").to_pandas()\n        st.session_state[\"eff_df\"] = df\n    return st.session_state[\"eff_df\"]\n\n# Button to clear cache so next load hits Snowflake again\nif st.button(\"ðŸ”„ Refresh data from Snowflake\"):\n    st.session_state.pop(\"eff_df\", None)\n    st.success(\"Data cache cleared. Latest data will be loaded from Snowflake on this run.\")\n\n# ---------------------------------------------\n# Load Gold efficiency table\n# ---------------------------------------------\neff_df = load_efficiency_df()\n\n# Ensure LOAD_DATE is full datetime (keep time, no .dt.date)\neff_df[\"LOAD_DATE\"] = pd.to_datetime(eff_df[\"LOAD_DATE\"])\n\n# ---------------------------------------------\n# Select snapshot (date + time)\n# ---------------------------------------------\navailable_snapshots = sorted(eff_df[\"LOAD_DATE\"].dropna().unique())\n\nif len(available_snapshots) == 0:\n    st.info(\"No LOAD_DATE values found in CHANNEL_EFFICIENCY_LEADERBOARD.\")\nelse:\n    selected_snapshot = st.selectbox(\n        \"Load Date / Time\",\n        options=available_snapshots,\n        index=len(available_snapshots) - 1,  # default: latest snapshot\n        format_func=lambda x: x.strftime(\"%Y-%m-%d %H:%M:%S\"),\n        key=\"size_dist_load_datetime\",\n    )\n\n    # Filter to selected snapshot\n    snap = eff_df[eff_df[\"LOAD_DATE\"] == selected_snapshot].copy()\n\n    # Drop null subs just in case\n    snap = snap[snap[\"SUBSCRIBER_COUNT\"].notna()]\n\n    if snap.empty:\n        st.info(\"No subscriber data available for the selected load date/time.\")\n    else:\n        # ---------------------------------------------\n        # Bucket channels by subscriber count\n        # ---------------------------------------------\n        bins = [0, 100_000, 1_000_000, 10_000_000, float(\"inf\")]\n        labels = [\n            \"< 100K (Emerging)\",\n            \"100Kâ€“1M (Growing)\",\n            \"1Mâ€“10M (Established)\",\n            \"> 10M (Mega)\"\n        ]\n\n        snap[\"SIZE_BUCKET\"] = pd.cut(\n            snap[\"SUBSCRIBER_COUNT\"],\n            bins=bins,\n            labels=labels,\n            right=False\n        )\n\n        bucket_stats = (\n            snap.groupby(\"SIZE_BUCKET\")\n            .agg(\n                CHANNEL_COUNT=(\"CHANNEL_NAME\", \"count\"),\n                AVG_SUBS=(\"SUBSCRIBER_COUNT\", \"mean\")\n            )\n            .reset_index()\n            .sort_values(\"CHANNEL_COUNT\", ascending=False)\n        )\n\n        st.write(\n            \"Selected snapshot: **{}**\".format(\n                selected_snapshot.strftime(\"%Y-%m-%d %H:%M:%S\")\n            )\n        )\n\n        # Summary table\n        st.dataframe(bucket_stats, use_container_width=True)\n\n        # ---------------------------------------------\n        # Donut chart of channel counts by size bucket\n        # ---------------------------------------------\n        st.vega_lite_chart(\n            bucket_stats,\n            {\n                \"mark\": {\"type\": \"arc\", \"innerRadius\": 60},\n                \"encoding\": {\n                    \"theta\": {\"field\": \"CHANNEL_COUNT\", \"type\": \"quantitative\"},\n                    \"color\": {\n                        \"field\": \"SIZE_BUCKET\",\n                        \"type\": \"nominal\",\n                        \"title\": \"Channel Size\",\n                        \"legend\": {\"orient\": \"right\"},\n                    },\n                    \"tooltip\": [\n                        {\"field\": \"SIZE_BUCKET\", \"type\": \"nominal\", \"title\": \"Bucket\"},\n                        {\n                            \"field\": \"CHANNEL_COUNT\",\n                            \"type\": \"quantitative\",\n                            \"title\": \"Number of Channels\",\n                        },\n                        {\n                            \"field\": \"AVG_SUBS\",\n                            \"type\": \"quantitative\",\n                            \"title\": \"Avg Subscribers\",\n                            \"format\": \",.0f\",\n                        },\n                    ],\n                },\n            },\n            use_container_width=True,\n        )\n\n        st.caption(\n            \"Channels are grouped into size buckets based on subscriber count using \"\n            \"GOLD.CHANNEL_EFFICIENCY_LEADERBOARD. This shows how skewed the ecosystem is \"\n            \"toward a small number of very large channels.\"\n        )\n",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "c695373e-ac74-4b62-a1f1-08206cbd5c81",
   "metadata": {
    "language": "python",
    "name": "cell3",
    "codeCollapsed": false
   },
   "source": "",
   "execution_count": null,
   "outputs": []
  }
 ]
}